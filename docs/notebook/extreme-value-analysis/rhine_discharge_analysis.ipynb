{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Rhine River Discharge Analysis using Statista Distributions\n",
    "\n",
    "This notebook demonstrates how to use the statista.distributions module to analyze discharge time series data from the Rhine River. We'll explore different probability distributions, fit them to the data, and calculate return periods and flood frequency curves.\n",
    "\n",
    "The Rhine River is one of Europe's major rivers, flowing through several countries including Switzerland, Liechtenstein, Austria, Germany, France and the Netherlands. Analyzing discharge data is crucial for flood risk assessment, water resource management, and understanding the hydrological behavior of the river.\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load and preprocess discharge time series data from multiple gauges along the Rhine River\n",
    "2. Fit different probability distributions to the data\n",
    "3. Evaluate the goodness of fit for each distribution\n",
    "4. Calculate return periods and flood frequency curves\n",
    "5. Visualize the results\n"
   ],
   "id": "6659269c9f1cb132"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import statista distributions module\n",
    "from statista.distributions import Distributions, PlottingPosition, Gumbel, GEV, Exponential, Normal\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Display all columns in pandas DataFrames\n",
    "pd.set_option('display.max_columns', None)\n"
   ],
   "id": "babe0a413077ecd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "We'll load the Rhine River discharge data from the CSV file. The data contains daily discharge measurements from multiple gauges along the river. The first column is the date, and the remaining columns represent different gauges.\n",
    "\n",
    "We need to handle missing values (empty strings) in the data and convert the date column to a datetime format. This preprocessing step is crucial for ensuring the quality of our analysis.\n"
   ],
   "id": "80ec13de23141b80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess the Rhine River discharge data.\n",
    "\n",
    "    - Reads a CSV file with a 'date' column and discharge columns for each gauge.\n",
    "    - Parses the date column into `datetime` objects and sets it as the index.\n",
    "    - Converts empty strings to NaN and casts all gauge columns to floats.\n",
    "    - Returns a clean `DataFrame` ready for analysis.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file containing the discharge data\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Preprocessed discharge data\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Display the first few rows of the data\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Convert the date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Set the date column as the index\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nNumber of missing values in each column:\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # Convert empty strings to NaN\n",
    "    df = df.replace('', np.nan)\n",
    "    \n",
    "    # Convert all columns to numeric\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Check for missing values again\n",
    "    print(\"\\nNumber of missing values after conversion:\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define the path to the data file\n",
    "file_path = '../../../examples/data/rhine-full-time-series.csv'\n",
    "\n",
    "# Load and preprocess the data\n",
    "print(\"Loading and preprocessing the data...\")\n",
    "df = load_and_preprocess_data(file_path)\n"
   ],
   "id": "22b1fe8a76907985",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's explore the data to understand the discharge patterns at different gauges along the Rhine River. We'll visualize the time series, examine the distribution of discharge values, and identify any seasonal patterns.\n",
    "\n",
    "Time series analysis helps us understand how discharge varies over time, while histograms provide insights into the statistical distribution of discharge values. This exploratory analysis is essential for selecting appropriate probability distributions for modeling.\n"
   ],
   "id": "87582debff9ee92f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_time_series(df, selected_gauges):\n",
    "    \"\"\"\n",
    "    Plot time series for selected gauges.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the discharge data\n",
    "        selected_gauges: List of gauge names to plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for gauge in selected_gauges:\n",
    "        if gauge in df.columns:\n",
    "            plt.plot(df.index, df[gauge], label=gauge)\n",
    "    plt.title('Discharge Time Series for Selected Gauges')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Discharge (m³/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_histograms(df, selected_gauges):\n",
    "    \"\"\"\n",
    "    Create histograms for selected gauges.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the discharge data\n",
    "        selected_gauges: List of gauge names to plot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, gauge in enumerate(selected_gauges):\n",
    "        if gauge in df.columns and i < len(axes):\n",
    "            # Use matplotlib's histogram function\n",
    "            data = df[gauge].dropna()\n",
    "            axes[i].hist(data, bins=20, density=True, alpha=0.7)\n",
    "            \n",
    "            # Add a density curve\n",
    "            from scipy import stats\n",
    "            min_val, max_val = data.min(), data.max()\n",
    "            x = np.linspace(min_val, max_val, 1000)\n",
    "            kde = stats.gaussian_kde(data)\n",
    "            axes[i].plot(x, kde(x), 'r-', linewidth=2)\n",
    "            \n",
    "            axes[i].set_title(f'Distribution of Discharge at {gauge}')\n",
    "            axes[i].set_xlabel('Discharge (m³/s)')\n",
    "            axes[i].set_ylabel('Density')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define selected gauges for analysis\n",
    "selected_gauges = ['rees', 'cologne', 'kaub', 'mainz']\n",
    "\n",
    "# Plot time series\n",
    "print(\"\\nPlotting time series for selected gauges...\")\n",
    "plot_time_series(df, selected_gauges)\n",
    "\n",
    "# Plot histograms\n",
    "print(\"\\nPlotting histograms for selected gauges...\")\n",
    "plot_histograms(df, selected_gauges)\n"
   ],
   "id": "71b1c8c35279ec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Annual Maximum Discharge Analysis\n",
    "\n",
    "For flood frequency analysis, we typically focus on annual maximum discharge values. This approach, known as the Annual Maximum Series (AMS) method, is widely used in hydrology for estimating the probability of extreme flood events.\n",
    "\n",
    "By extracting the maximum discharge value for each year, we create a dataset that represents the most extreme conditions observed annually. This dataset is then used to fit probability distributions that model the frequency of extreme events.\n"
   ],
   "id": "4aeae6ca4cf2e477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_annual_maxima(df):\n",
    "    \"\"\"\n",
    "    Extract annual maximum discharge for each gauge.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the discharge data\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Annual maximum discharge for each gauge\n",
    "    \"\"\"\n",
    "    # Extract annual maximum discharge for each gauge\n",
    "    annual_max = df.resample('YE').max()\n",
    "    \n",
    "    return annual_max\n",
    "\n",
    "def plot_annual_maxima(annual_max, selected_gauges):\n",
    "    \"\"\"\n",
    "    Plot annual maximum discharge for selected gauges.\n",
    "    \n",
    "    Args:\n",
    "        annual_max: DataFrame containing annual maximum discharge\n",
    "        selected_gauges: List of gauge names to plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for gauge in selected_gauges:\n",
    "        if gauge in annual_max.columns:\n",
    "            plt.plot(annual_max.index, annual_max[gauge], 'o-', label=gauge)\n",
    "    plt.title('Annual Maximum Discharge for Selected Gauges')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Maximum Discharge (m³/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Extract annual maximum discharge\n",
    "print(\"\\nExtracting annual maximum discharge...\")\n",
    "annual_max = extract_annual_maxima(df)\n",
    "\n",
    "# Plot annual maximum discharge\n",
    "print(\"\\nPlotting annual maximum discharge for selected gauges...\")\n",
    "plot_annual_maxima(annual_max, selected_gauges)\n"
   ],
   "id": "33a38d93573157d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fitting Probability Distributions\n",
    "\n",
    "Now we'll fit different probability distributions to the annual maximum discharge data for each gauge. We'll use the following distributions from the statista.distributions module:\n",
    "\n",
    "1. **Gumbel distribution**: Also known as the Extreme Value Type I distribution, it's commonly used for modeling maximum values, such as annual flood peaks.\n",
    "\n",
    "2. **Generalized Extreme Value (GEV) distribution**: A flexible three-parameter distribution that encompasses the Gumbel, Fréchet, and Weibull distributions, making it suitable for modeling extreme events.\n",
    "\n",
    "3. **Normal distribution**: While not typically used for extreme values, it serves as a baseline for comparison.\n",
    "\n",
    "4. **Exponential distribution**: Often used for modeling the time between events in a Poisson process, but can also be applied to certain hydrological variables.\n",
    "\n",
    "We'll evaluate the goodness of fit using the Kolmogorov-Smirnov test, which measures the maximum difference between the empirical and theoretical cumulative distribution functions.\n"
   ],
   "id": "603d4a2ea3ff5a3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fit_distributions(data, method=\"lmoments\"):\n",
    "    \"\"\"\n",
    "    Fit different distributions to the data and evaluate goodness of fit.\n",
    "    \n",
    "    Args:\n",
    "        data: numpy array of discharge values\n",
    "        method: fitting method ('mle' for Maximum Likelihood Estimation or 'lmoments' for L-moments)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of fitted distribution objects and test results\n",
    "    \"\"\"\n",
    "    # Remove NaN values\n",
    "    data = data[~np.isnan(data)]\n",
    "    \n",
    "    # Sort data in ascending order\n",
    "    data = np.sort(data)\n",
    "    \n",
    "    # Initialize distributions\n",
    "    gumbel = Gumbel(data=data)\n",
    "    gev = GEV(data=data)\n",
    "    normal = Normal(data=data)\n",
    "    exponential = Exponential(data=data)\n",
    "    \n",
    "    # Fit distributions\n",
    "    gumbel_params = gumbel.fit_model(method=method)\n",
    "    gev_params = gev.fit_model(method=method)\n",
    "    normal_params = normal.fit_model(method=method)\n",
    "    exponential_params = exponential.fit_model(method=method)\n",
    "    \n",
    "    # Perform Kolmogorov-Smirnov test\n",
    "    gumbel_ks = gumbel.ks()\n",
    "    gev_ks = gev.ks()\n",
    "    normal_ks = normal.ks()\n",
    "    exponential_ks = exponential.ks()\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'Gumbel': {'dist': gumbel, 'params': gumbel_params, 'ks': gumbel_ks},\n",
    "        'GEV': {'dist': gev, 'params': gev_params, 'ks': gev_ks},\n",
    "        'Normal': {'dist': normal, 'params': normal_params, 'ks': normal_ks},\n",
    "        'Exponential': {'dist': exponential, 'params': exponential_params, 'ks': exponential_ks}\n",
    "    }\n",
    "\n",
    "#Example usage:\n",
    "for gauge in selected_gauges:\n",
    "    if gauge in annual_max.columns:\n",
    "        data = annual_max[gauge].values\n",
    "        results = fit_distributions(data)\n"
   ],
   "id": "369412cac3406a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Visualizing Fitted Distributions\n",
    "\n",
    "After fitting the distributions, it's important to visualize how well they match the empirical data. We'll create plots of both the probability density function (PDF) and the cumulative distribution function (CDF) for each distribution.\n",
    "\n",
    "The PDF shows the relative likelihood of different discharge values, while the CDF shows the probability of not exceeding a given discharge value. These visualizations help us assess which distribution provides the best fit to the observed data.\n"
   ],
   "id": "f6c06c4309ee5b5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_fitted_distributions(data, fitted_dists, gauge_name):\n",
    "    \"\"\"\n",
    "    Plot the empirical and fitted distributions.\n",
    "    \n",
    "    Args:\n",
    "        data: numpy array of discharge values\n",
    "        fitted_dists: dictionary of fitted distribution objects\n",
    "        gauge_name: name of the gauge\n",
    "    \"\"\"\n",
    "    # Remove NaN values\n",
    "    data = data[~np.isnan(data)]\n",
    "    \n",
    "    # Sort data in ascending order\n",
    "    data = np.sort(data)\n",
    "    \n",
    "    # Calculate empirical CDF using Weibull plotting position\n",
    "    pp = PlottingPosition.weibul(data)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot PDF\n",
    "    ax1.hist(data, bins=20, density=True, alpha=0.5, label='Empirical')\n",
    "    x = np.linspace(min(data), max(data), 1000)\n",
    "    \n",
    "    for name, dist_info in fitted_dists.items():\n",
    "        dist = dist_info['dist']\n",
    "        params = dist_info['params']\n",
    "        \n",
    "        # Plot PDF\n",
    "        # y_pdf = dist._pdf_eq(x, params)\n",
    "        y_pdf = dist.pdf(data=x, parameters=params)\n",
    "        ax1.plot(x, y_pdf, label=f'{name} (KS p-value: {dist_info[\"ks\"][1]:.4f})')\n",
    "    \n",
    "    ax1.set_title(f'Probability Density Function - {gauge_name}')\n",
    "    ax1.set_xlabel('Discharge (m³/s)')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot CDF\n",
    "    ax2.plot(data, pp, 'o', label='Empirical')\n",
    "    \n",
    "    for name, dist_info in fitted_dists.items():\n",
    "        dist = dist_info['dist']\n",
    "        params = dist_info['params']\n",
    "        \n",
    "        # Plot CDF\n",
    "        y_cdf = dist.cdf(data=x, parameters=params)\n",
    "        ax2.plot(x, y_cdf, label=f'{name} (KS p-value: {dist_info[\"ks\"][1]:.4f})')\n",
    "    \n",
    "    ax2.set_title(f'Cumulative Distribution Function - {gauge_name}')\n",
    "    ax2.set_xlabel('Discharge (m³/s)')\n",
    "    ax2.set_ylabel('Probability of Non-Exceedance')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "abde5b9da18cb0f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Flood Frequency Analysis\n",
    "\n",
    "Flood frequency analysis is a statistical technique used to estimate the probability of occurrence of a given discharge magnitude. The results are typically expressed in terms of return periods, which represent the average time interval between events of a given magnitude.\n",
    "\n",
    "The flood frequency curve plots discharge values against their corresponding return periods. This curve is a valuable tool for flood risk assessment and the design of hydraulic structures.\n"
   ],
   "id": "403f25f50371cd15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_flood_frequency_curve(data, fitted_dists, gauge_name):\n",
    "    \"\"\"\n",
    "    Calculate return periods and plot flood frequency curves.\n",
    "    \n",
    "    Args:\n",
    "        data: numpy array of discharge values\n",
    "        fitted_dists: dictionary of fitted distribution objects\n",
    "        gauge_name: name of the gauge\n",
    "    \"\"\"\n",
    "    # Remove NaN values\n",
    "    data = data[~np.isnan(data)]\n",
    "    \n",
    "    # Sort data in ascending order\n",
    "    data = np.sort(data)\n",
    "    \n",
    "    # Calculate empirical return periods using Weibull plotting position\n",
    "    pp = PlottingPosition.weibul(data)\n",
    "    rp = PlottingPosition.return_period(pp)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot empirical return periods\n",
    "    plt.semilogx(rp, data, 'o', label='Empirical')\n",
    "    \n",
    "    # Generate return periods for plotting\n",
    "    return_periods = np.logspace(0, 3, 1000)  # 1 to 1000 years\n",
    "    non_exceed_prob = 1 - 1/return_periods\n",
    "    \n",
    "    # Plot theoretical return periods for each distribution\n",
    "    for name, dist_info in fitted_dists.items():\n",
    "        dist = dist_info['dist']\n",
    "        params = dist_info['params']\n",
    "        \n",
    "        # Calculate quantiles for each return period\n",
    "        quantiles = dist.inverse_cdf(non_exceed_prob, params)\n",
    "        \n",
    "        # Plot flood frequency curve\n",
    "        plt.semilogx(return_periods, quantiles, label=name)\n",
    "    \n",
    "    plt.title(f'Flood Frequency Curve - {gauge_name}')\n",
    "    plt.xlabel('Return Period (years)')\n",
    "    plt.ylabel('Discharge (m³/s)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add vertical lines for common return periods\n",
    "    common_rp = [2, 5, 10, 25, 50, 100, 200, 500]\n",
    "    for rp_val in common_rp:\n",
    "        plt.axvline(x=rp_val, color='gray', linestyle='--', alpha=0.5)\n",
    "        plt.text(rp_val, plt.ylim()[0], str(rp_val), ha='center', va='bottom', alpha=0.7)\n",
    "    \n",
    "    plt.show()\n"
   ],
   "id": "77c5dc75771f4b04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_distributions(annual_max, selected_gauges):\n",
    "    \"\"\"\n",
    "    Fit distributions to annual maximum discharge for selected gauges.\n",
    "    \n",
    "    Args:\n",
    "        annual_max: DataFrame containing annual maximum discharge\n",
    "        selected_gauges: List of gauge names to analyze\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of fitted distribution results for each gauge\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for gauge in selected_gauges:\n",
    "        if gauge in annual_max.columns:\n",
    "            print(f\"\\nFitting distributions to {gauge}...\")\n",
    "            data = annual_max[gauge].values\n",
    "            results[gauge] = fit_distributions(data)\n",
    "            \n",
    "            # Print goodness of fit results\n",
    "            print(f\"\\nGoodness of fit results for {gauge}:\")\n",
    "            for dist_name, dist_info in results[gauge].items():\n",
    "                ks_stat = dist_info['ks'][0]\n",
    "                ks_pvalue = dist_info['ks'][1]\n",
    "                print(f\"{dist_name}: KS statistic = {ks_stat:.4f}, p-value = {ks_pvalue:.4f}\")\n",
    "            \n",
    "            # Plot fitted distributions\n",
    "            plot_fitted_distributions(data, results[gauge], gauge)\n",
    "            \n",
    "            # Plot flood frequency curve\n",
    "            plot_flood_frequency_curve(data, results[gauge], gauge)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Fit distributions and analyze results\n",
    "print(\"\\nFitting distributions and analyzing results...\")\n",
    "results = analyze_distributions(annual_max, selected_gauges)\n"
   ],
   "id": "e13ab5449d4a8d1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Design Floods\n",
    "\n",
    "Design floods are discharge values associated with specific return periods. They are used in the design of hydraulic structures, flood protection measures, and risk assessment.\n",
    "\n",
    "For example, a 100-year flood (a flood with a 1% annual probability of occurrence) is often used as a design standard for major infrastructure. By calculating design floods for different return periods, we can provide valuable information for flood risk management and infrastructure planning.\n"
   ],
   "id": "862ea5ea1218afa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_best_distribution(fitted_dists):\n",
    "    \"\"\"\n",
    "    Find the best-fitting distribution based on KS test p-value.\n",
    "    \n",
    "    Args:\n",
    "        fitted_dists: dictionary of fitted distribution objects\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best distribution name, distribution info)\n",
    "    \"\"\"\n",
    "    best_dist = None\n",
    "    best_pvalue = -1\n",
    "    \n",
    "    for name, dist_info in fitted_dists.items():\n",
    "        pvalue = dist_info['ks'][1]\n",
    "        if pvalue > best_pvalue:\n",
    "            best_pvalue = pvalue\n",
    "            best_dist = (name, dist_info)\n",
    "    \n",
    "    return best_dist\n",
    "\n",
    "def calculate_design_floods(results):\n",
    "    \"\"\"\n",
    "    Calculate design floods for common return periods.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary of fitted distribution results for each gauge\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Design floods for different return periods\n",
    "    \"\"\"\n",
    "    common_rp = [2, 5, 10, 25, 50, 100, 200, 500, 1000]\n",
    "    design_floods = {}\n",
    "    \n",
    "    for gauge, fitted_dists in results.items():\n",
    "        best_dist_name, best_dist_info = find_best_distribution(fitted_dists)\n",
    "        dist = best_dist_info['dist']\n",
    "        params = best_dist_info['params']\n",
    "        \n",
    "        # Calculate non-exceedance probabilities for common return periods\n",
    "        non_exceed_prob = 1 - 1/np.array(common_rp)\n",
    "        \n",
    "        # Calculate quantiles (design floods)\n",
    "        quantiles = dist.inverse_cdf(non_exceed_prob, params)\n",
    "        \n",
    "        # Store results\n",
    "        design_floods[gauge] = {\n",
    "            'best_dist': best_dist_name,\n",
    "            'return_periods': common_rp,\n",
    "            'design_floods': quantiles\n",
    "        }\n",
    "    \n",
    "    # Create a DataFrame to display design floods\n",
    "    design_flood_df = pd.DataFrame(index=common_rp)\n",
    "    for gauge, info in design_floods.items():\n",
    "        design_flood_df[f\"{gauge} ({info['best_dist']})\"] = info['design_floods']\n",
    "    \n",
    "    design_flood_df.index.name = 'Return Period (years)'\n",
    "    design_flood_df.columns.name = 'Gauge (Best Distribution)'\n",
    "    \n",
    "    return design_flood_df\n",
    "\n",
    "# Calculate design floods\n",
    "print(\"\\nCalculating design floods...\")\n",
    "design_flood_df = calculate_design_floods(results)\n",
    "print(\"\\nDesign Floods (m³/s) for Different Return Periods:\")\n",
    "print(design_flood_df)\n"
   ],
   "id": "c68d410afb27a101",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Flood Frequency Curves with Uncertainty\n",
    "\n",
    "When estimating flood frequencies, it's important to acknowledge the uncertainty in our predictions. This uncertainty increases for larger return periods, as we're extrapolating beyond the range of observed data.\n",
    "\n",
    "Due to limitations in the current implementation, we'll skip the confidence interval calculation, but in a complete analysis, you would want to include confidence intervals to show the uncertainty in the flood frequency estimates.\n"
   ],
   "id": "1ae5336cea068172"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_flood_frequency_with_ci(data, fitted_dists, gauge_name):\n",
    "    \"\"\"\n",
    "    Plot flood frequency curve with simplified uncertainty representation.\n",
    "    \n",
    "    Args:\n",
    "        data: numpy array of discharge values\n",
    "        fitted_dists: dictionary of fitted distribution objects\n",
    "        gauge_name: name of the gauge\n",
    "    \"\"\"\n",
    "    # Remove NaN values\n",
    "    data = data[~np.isnan(data)]\n",
    "    \n",
    "    # Sort data in ascending order\n",
    "    data = np.sort(data)\n",
    "    \n",
    "    # Calculate empirical return periods using Weibull plotting position\n",
    "    pp = PlottingPosition.weibul(data)\n",
    "    rp = PlottingPosition.return_period(pp)\n",
    "    \n",
    "    # Find best distribution\n",
    "    best_dist_name, best_dist_info = find_best_distribution(fitted_dists)\n",
    "    dist = best_dist_info['dist']\n",
    "    params = best_dist_info['params']\n",
    "    \n",
    "    # Generate return periods for plotting\n",
    "    return_periods = np.logspace(0, 3, 1000)  # 1 to 1000 years\n",
    "    non_exceed_prob = 1 - 1/return_periods\n",
    "\n",
    "    # Calculate confidence intervals\n",
    "    ci = dist.confidence_interval(alpha=0.1, prob_non_exceed=non_exceed_prob)\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot empirical return periods\n",
    "    plt.semilogx(rp, data, 'o', label='Empirical')\n",
    "    \n",
    "    # Calculate quantiles for each return period\n",
    "    quantiles = dist.inverse_cdf(non_exceed_prob, params)\n",
    "    \n",
    "    # Plot flood frequency curve\n",
    "    plt.semilogx(return_periods, quantiles, label=best_dist_name)\n",
    "\n",
    "    # Plot confidence intervals\n",
    "    plt.fill_between(return_periods, ci[1], ci[0], alpha=0.2, label='90% Confidence Interval')\n",
    "    \n",
    "    plt.title(f'Flood Frequency Curve - {gauge_name} (Best Fit: {best_dist_name})')\n",
    "    plt.xlabel('Return Period (years)')\n",
    "    plt.ylabel('Discharge (m³/s)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add vertical lines for common return periods\n",
    "    common_rp = [2, 5, 10, 25, 50, 100, 200, 500, 1000]\n",
    "    for rp_val in common_rp:\n",
    "        plt.axvline(x=rp_val, color='gray', linestyle='--', alpha=0.5)\n",
    "        plt.text(rp_val, plt.ylim()[0], str(rp_val), ha='center', va='bottom', alpha=0.7)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_confidence_intervals(annual_max, results, selected_gauges):\n",
    "    \"\"\"\n",
    "    Plot flood frequency curves with simplified uncertainty representation for selected gauges.\n",
    "    \n",
    "    Args:\n",
    "        annual_max: DataFrame containing annual maximum discharge\n",
    "        results: Dictionary of fitted distribution results for each gauge\n",
    "        selected_gauges: List of gauge names to plot\n",
    "    \"\"\"\n",
    "    for gauge in selected_gauges:\n",
    "        if gauge in results:\n",
    "            print(f\"\\nPlotting flood frequency curve for {gauge}...\")\n",
    "            data = annual_max[gauge].values\n",
    "            plot_flood_frequency_with_ci(data, results[gauge], gauge)\n",
    "\n",
    "# Plot flood frequency curves with simplified uncertainty representation\n",
    "print(\"\\nPlotting flood frequency curves...\")\n",
    "plot_confidence_intervals(annual_max, results, selected_gauges)\n"
   ],
   "id": "9b0dcd38a46fab92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "In this notebook, we've demonstrated how to use the statista.distributions module to analyze discharge time series data from the Rhine River. We've explored different probability distributions, fitted them to the data, and calculated return periods and flood frequency curves.\n",
    "\n",
    "Key findings:\n",
    "- The best-fitting distribution varies between gauges, highlighting the importance of testing multiple distributions\n",
    "- The GEV and Gumbel distributions generally provide good fits for annual maximum discharge data, which is consistent with extreme value theory\n",
    "- Design floods increase with return period, but the rate of increase varies between gauges\n",
    "- Uncertainty in flood frequency estimates increases for larger return periods\n",
    "\n",
    "This analysis provides valuable information for flood risk assessment, water resource management, and the design of hydraulic structures along the Rhine River.\n"
   ],
   "id": "73288d54d1117db5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print a summary of the analysis\n",
    "print(\"\\nAnalysis complete!\")\n",
    "\n",
    "# Summary of findings\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"- The best-fitting distribution varies between gauges, highlighting the importance of testing multiple distributions\")\n",
    "print(\"- The GEV and Gumbel distributions generally provide good fits for annual maximum discharge data, which is consistent with extreme value theory\")\n",
    "print(\"- Design floods increase with return period, but the rate of increase varies between gauges\")\n",
    "print(\"- Uncertainty in flood frequency estimates increases for larger return periods, though we couldn't visualize this due to implementation limitations\")"
   ],
   "id": "69a9bd4d879f68ec",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
